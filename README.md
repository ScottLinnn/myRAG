# myRAG

Studying LLM from the angle of RAG as start point.

## References: 

- [Retrieval-Augmented Generation for Large Language Models: A Survey](https://arxiv.org/abs/2312.10997)
- [Pinecone's tutorial on VDB](https://www.pinecone.io/learn/vector-database/)
- [LangChain's list of vector databases](https://python.langchain.com/docs/integrations/vectorstores)
- [LlamaIndex's tutorial on building a retriever](https://docs.llamaindex.ai/en/stable/examples/low_level/retrieval.html) (llama_idx_sample.ipynb copied this)
- [CMU-DB seminar in 23 Fall](https://db.cs.cmu.edu/seminar2023/) has a lot of VDBs
- There seems to be a lot of good code in HuggingFace community, for example I found [this one](https://huggingface.co/spaces/ubermenchh/article_chat/blob/main/app.py) intuitive to understand
- [Comparison between fine-tuning and RAG](https://www.superannotate.com/blog/llm-fine-tuning)
